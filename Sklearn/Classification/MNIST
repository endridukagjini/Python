# MNIST
from sklearn.datasets import fetch_openml
import matplotlib.pyplot as plt
from sklearn.linear_model import SGDClassifier
from sklearn.model_selection import cross_val_score
from sklearn.dummy import DummyClassifier
from sklearn.model_selection import StratifiedKFold
from sklearn.base import clone
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import precision_recall_curve
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.multiclass import OneVsRestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import ConfusionMatrixDisplay



mnist = fetch_openml('mnist_784', as_frame = False)

X, y = mnist.data, mnist.target

X.shape
y.shape
y
X

def plot_digit(image_data):
    image = image_data.reshape(28,28)
    plt.imshow(image, cmap = "binary")
    plt.axis("off")

some_digit = X[0]
plot_digit(some_digit)
plt.show()

y[0]

X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]

# 5 or not 5

y_train_5 = (y_train == '5') # True for all 5s, False for all other digits
y_test_5 = (y_test == '5')

sgd_clf = SGDClassifier(random_state = 42)
sgd_clf.fit(X_train, y_train_5)

sgd_clf.predict([some_digit])

cross_val_score(sgd_clf, X_train, y_train_5, cv = 3, scoring = "accuracy")

skfolds = StratifiedKFold(n_splits = 3) # add shuffle = True if the dataset is not already shyffled

for train_index, test_index in skfolds.split(X_train, y_train_5):
    clone_clf = clone(sgd_clf)
    X_train_folds = X_train[train_index]
    y_train_folds = y_train_5[train_index]
    X_test_fold = X_train[test_index]
    y_test_fold = y_train_5[test_index]

    clone_clf.fit(X_train_folds, y_train_folds)
    y_pred = clone_clf.predict(X_test_fold)
    n_correct = sum(y_pred == y_test_fold)
    print (n_correct / len(y_pred))


y_train_pred = cross_val_predict(sgd_clf,X_train, y_train_5, cv = 3)

cm = confusion_matrix(y_train_5, y_train_pred)
cm

y_train_perfect_predictions = y_train_5 # pretend we reached prefection
confusion_matrix(y_train_5, y_train_perfect_predictions)

# Precision = true positive / (true positive + false positive)

# Recall = true positive / ( true positive + false negative)

precision_score(y_train_5, y_train_pred)

recall_score(y_train_5, y_train_pred)

# f1 score = 2 * ( precision * recall) / ( precision + recall)

f1_score(y_train_5, y_train_pred)


y_scores = sgd_clf.decision_function([some_digit])
y_scores

threshold = 0
y_some_digit_pred = (y_scores > threshold)

threshold = 3000
y_some_digit_pred = (y_scores > threshold)
y_some_digit_pred

y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv = 3, method = "decision_function")

precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)

plt.plot(thresholds, precisions[:-1], "b--", label="Precision", linewidth=2)
plt.plot(thresholds, recalls[:-1], label = "Recall", linewidth = 2)
plt.vlines(threshold, 0, 1.0, "k", "dotted", label = "threshold")
plt.show()

plt.plot(recalls, precisions, linewidth = 2, label = "Precision/Recall curve")
plt.show()


idx_for_90_precision = (precisions>=0.90).argmax()
threshold_for_90_precision = thresholds[idx_for_90_precision]
threshold_for_90_precision

y_train_pred_90 = (y_scores >= threshold_for_90_precision)

precision_score(y_train_5, y_train_pred_90)

recall_at_90_precision = recall_score(y_train_5, y_train_pred_90)
recall_at_90_precision

fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)

idx_for_threshold_at_90 = (thresholds <= threshold_for_90_precision).argmax()
tpr_90, fpr_90 = tpr[idx_for_threshold_at_90], fpr[idx_for_threshold_at_90]

plt.plot(fpr,tpr,linewidth=2, label = "Roc curve")
plt.plot([0,1],[0,1],"k:", label = "Random classifier's ROC curve")
plt.plot([fpr_90],[tpr_90], "ko", label = "Treshold for 90% precision")
plt.show()


roc_auc_score(y_train_5, y_scores)

forest_clf = RandomForestClassifier(random_state = 42)

y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv = 3, method = "predict_proba")

y_probas_forest[:2]

y_scores_forest = y_probas_forest[:,1]
precisions_forest, recall_forest, thresholds_forest = precision_recall_curve(y_train_5, y_scores_forest)

plt.plot(recall_forest, precisions_forest, "b-", linewidth=2, label = "Random forest")
plt.plot(recalls, precisions, "--", linewidth =2, label = "SGD")
plt.show()

y_train_pred_forest = y_probas_forest[:,1]>= 0.5 # positive proba >= 50%
f1_score(y_train_5, y_train_pred_forest)
roc_auc_score(y_train_5, y_scores_forest)

svm_clf = SVC(random_state = 42)

svm_clf.fit(X_train[:2000], y_train[:2000]) # y_train, not y_train_5

svm_clf.predict([some_digit])

some_digit_scores = svm_clf.decision_function([some_digit])
some_digit_scores.round(2)

class_id = some_digit_scores.argmax()
class_id

svm_clf.classes_

svm_clf.classes_[class_id]

ovr_clf = OneVsRestClassifier(SVC(random_state = 42))
ovr_clf.fit(X_train[:2000], y_train[:2000])

ovr_clf.predict([some_digit])

len(ovr_clf.estimators_)

# sgdclassifier

sgd_clf = SGDClassifier(random_state = 42)
sgd_clf.fit(X_train, y_train)
sgd_clf.predict([some_digit])

sgd_clf.decision_function([some_digit]).round()

cross_val_score(sgd_clf, X_train, y_train, cv = 3, scoring = "accuracy")

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train.astype("flat64"))
cross_val_score(sgd_clf, X_train_scaled, y_train, cv =3, scoring = "accuracy")

y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv = 3)
ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred)
plt.show()

ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred, normalize = "true", values_format=".0%")

sample_weight = (y_train_pred != y_train)
ConfusionMatrixDisplay.from_predictions(y_train, y_train_pred, sample_weight=sample_weight, normalize="true", values_format=".0%")
plt.show()





